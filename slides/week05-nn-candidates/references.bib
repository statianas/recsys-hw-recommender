@inproceedings{YTBE,
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
title = {Deep Neural Networks for YouTube Recommendations},
year = {2016},
isbn = {9781450340359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2959100.2959190},
doi = {10.1145/2959100.2959190},
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation
systems in existence. In this paper, we describe the system at a high level and focus
on the dramatic performance improvements brought by deep learning. The paper is split
according to the classic two-stage information retrieval dichotomy: first, we detail
a deep candidate generation model and then describe a separate deep ranking model.
We also provide practical lessons and insights derived from designing, iterating and
maintaining a massive recommendation system with enormous user-facing impact.},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
pages = {191–198},
numpages = {8},
keywords = {deep learning, recommender system, scalability},
location = {Boston, Massachusetts, USA},
series = {RecSys '16}
}

@misc{ANOKHIN, title={Как я перестал бояться и научился любить нейронные сети}, url={https://habr.com/ru/company/odnoklassniki/blog/525974/}, author={Анохин, Николай}, year={2020}
} 
 
@inproceedings{AIRBNB,
author = {Haldar, Malay and Abdool, Mustafa and Ramanathan, Prashant and Xu, Tao and Yang, Shulin and Duan, Huizhong and Zhang, Qing and Barrow-Williams, Nick and Turnbull, Bradley C. and Collins, Brendan M. and Legrand, Thomas},
title = {Applying Deep Learning to Airbnb Search},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330658},
doi = {10.1145/3292500.3330658},
abstract = {The application to search ranking is one of the biggest machine learning success stories
at Airbnb. Much of the initial gains were driven by a gradient boosted decision tree
model. The gains, however, plateaued over time. This paper discusses the work done
in applying neural networks in an attempt to break out of that plateau. We present
our perspective not with the intention of pushing the frontier of new modeling techniques.
Instead, ours is a story of the elements we found useful in applying neural networks
to a real life product. Deep learning was steep learning for us. To other teams embarking
on similar journeys, we hope an account of our struggles and triumphs will provide
some useful pointers. Bon voyage!},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1927–1935},
numpages = {9},
keywords = {deep learning, search ranking, e-commerce},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{NCF,
author = {He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng},
title = {Neural Collaborative Filtering},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052569},
doi = {10.1145/3038912.3052569},
abstract = {In recent years, deep neural networks have yielded immense success on speech recognition,
computer vision and natural language processing. However, the exploration of deep
neural networks on recommender systems has received relatively less scrutiny. In this
work, we strive to develop techniques based on neural networks to tackle the key problem
in recommendation --- collaborative filtering --- on the basis of implicit feedback.Although
some recent work has employed deep learning for recommendation, they primarily used
it to model auxiliary information, such as textual descriptions of items and acoustic
features of musics. When it comes to model the key factor in collaborative filtering
--- the interaction between user and item features, they still resorted to matrix
factorization and applied an inner product on the latent features of users and items.By
replacing the inner product with a neural architecture that can learn an arbitrary
function from data, we present a general framework named NCF, short for Neural network-based
Collaborative Filtering. NCF is generic and can express and generalize matrix factorization
under its framework. To supercharge NCF modelling with non-linearities, we propose
to leverage a multi-layer perceptron to learn the user-item interaction function.
Extensive experiments on two real-world datasets show significant improvements of
our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows
that using deeper layers of neural networks offers better recommendation performance.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {173–182},
numpages = {10},
keywords = {matrix factorization, neural networks, collaborative filtering, deep learning, implicit feedback},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{BERT4Rec,
 author = {Sun, Fei and Liu, Jun and Wu, Jian and Pei, Changhua and Lin, Xiao and Ou, Wenwu and Jiang, Peng},
 title = {BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer},
 booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
 series = {CIKM '19},
 year = {2019},
 isbn = {978-1-4503-6976-3},
 location = {Beijing, China},
 pages = {1441--1450},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3357384.3357895},
 doi = {10.1145/3357384.3357895},
 acmid = {3357895},
 publisher = {ACM},
 address = {New York, NY, USA}
} 

@inproceedings{DSSM,
author = {Huang, Po-Sen and He, Xiaodong and Gao, Jianfeng and Deng, Li and Acero, Alex and Heck, Larry},
title = {Learning Deep Structured Semantic Models for Web Search Using Clickthrough Data},
year = {2013},
isbn = {9781450322638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2505515.2505665},
doi = {10.1145/2505515.2505665},
abstract = {Latent semantic models, such as LSA, intend to map a query to its relevant documents
at the semantic level where keyword-based matching often fails. In this study we strive
to develop a series of new latent semantic models with a deep structure that project
queries and documents into a common low-dimensional space where the relevance of a
document given a query is readily computed as the distance between them. The proposed
deep structured semantic models are discriminatively trained by maximizing the conditional
likelihood of the clicked documents given a query using the clickthrough data. To
make our models applicable to large-scale Web search applications, we also use a technique
called word hashing, which is shown to effectively scale up our semantic models to
handle large vocabularies which are common in such tasks. The new models are evaluated
on a Web document ranking task using a real-world data set. Results show that our
best model significantly outperforms other latent semantic models, which were considered
state-of-the-art in the performance prior to the work presented in this paper.},
booktitle = {Proceedings of the 22nd ACM International Conference on Information and Knowledge Management},
pages = {2333–2338},
numpages = {6},
keywords = {web search, semantic model, deep learning, clickthrough data},
location = {San Francisco, California, USA},
series = {CIKM '13}
}

@inproceedings{DFN,
  title={Deep Feedback Network for Recommendation},
  author={Ruobing Xie and Chen Ling and Yalong Wang and Rui Wang and Feng Xia and Leyu Lin},
  booktitle={IJCAI},
  year={2020}
}

@misc{METH,
      title={Methodologies for Improving Modern Industrial Recommender Systems}, 
      author={Shusen Wang},
      year={2023},
      eprint={2308.01204},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{SSL,
      title={Self-supervised Learning for Large-scale Item Recommendations}, 
      author={Tiansheng Yao and Xinyang Yi and Derek Zhiyuan Cheng and Felix Yu and Ting Chen and Aditya Menon and Lichan Hong and Ed H. Chi and Steve Tjoa and Jieqi Kang and Evan Ettinger},
      year={2021},
      eprint={2007.12865},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
